**AI & Tech Developments: February 12–13, 2026**

Here's a concise, prioritized roundup of the most significant AI and tech news from the past 24 hours, focusing on model releases, research breakthroughs, and open-source advancements. I've organized it for quick scanning with tags where relevant.

### Model Releases
**OpenAI launches GPT-5.3-Codex-Spark** — An ultra-fast, real-time coding model (a streamlined variant of GPT-5.3-Codex) optimized for interactive development. It delivers over 1,000 tokens per second on Cerebras hardware, enabling near-instant feedback in tools like the Codex app, CLI, and VS Code. Available now in research preview for ChatGPT Pro users. This marks OpenAI's first production deployment on non-Nvidia chips.

**Zhipu AI (China) releases GLM-5** — A new open-weight flagship LLM with major gains in coding and long-running agentic tasks. It approaches Anthropic's Claude Opus 4.5 on benchmarks, uses only domestic Huawei Ascend chips (no Nvidia), and is positioned as a frontier model for complex engineering. Released Feb 11–12 amid a wave of Chinese AI launches.

**ByteDance unveils Seedance 2.0** — A multimodal video generation model that accepts text, images, audio, and video inputs simultaneously. It excels in motion stability, physics realism, and cinematic output, quickly going viral (praised by Elon Musk) for professional film/ad use. Launched Feb 10–12; already sparking Hollywood copyright concerns.

**OpenAI: GPT-5.2 makes a novel discovery in theoretical physics** — The model derived a new formula for single-minus gluon tree amplitudes (previously thought impossible under certain conditions). An internal model proved it, and human physicists verified the preprint. This is a rare case of frontier AI contributing original science.

### New Papers & Research
**Multiple arXiv papers on multi-agent systems** (submitted/updated ~Feb 12) — Highlights include:
- *AIRS-Bench*: A benchmark suite for frontier AI science agents across the full research lifecycle.
- *Position: Agentic Evolution is the Path to Evolving LLMs* — Argues for agent-driven self-improvement in models.
- Several on memory mechanisms, debate efficiency, and game-theoretic reasoning in agents (e.g., poker benchmarks).

**OpenScholar** — An open-source AI tool for scientific literature reviews that outperforms giant commercial LLMs on accuracy and citation fidelity. Fully reproducible and deployable locally; published in *Nature* (recent buzz).

### New Developments in Multi-Agent Frameworks
The arXiv cluster above directly advances this space, with papers on meta-agents, polarized memory for verifiable agents, and persuasion dynamics in LLM swarms. No major framework releases today, but the research momentum is clear.

### Everything Else
- **OpenAI retires legacy models** (GPT-4o, GPT-4.1 variants) from ChatGPT (API unaffected); GPT-5.2 is now dominant for most users.
- **Meta plans facial recognition ("Name Tag")** for Ray-Ban/Oakley smart glasses in 2026, raising privacy flags.
- **Market reaction to AI disruption fears** dominated headlines (software, media, logistics stocks hit), but no new tech announcements tied to it.
- Minor notes: Hackers targeted Gemini with 100k+ cloning prompts; Anthropic's Claude Cowork plugin (legal AI) continues rippling through enterprise.

No major blockchain-for-GenAI, regulatory, or enterprise LLM framework (e.g., Cowork/Frontier) announcements in the window. The day was heavy on model velocity from both US and Chinese labs.